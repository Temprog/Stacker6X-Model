# -*- coding: utf-8 -*-
"""03_data_splitting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n_IhtC_IWoLKrABiZUL8K2vt9h6E0tkX

# Data Splitting (to training & testing)
"""

# Imports from utils.imports
from utils.imports import pd, TfidfVectorizer, train_test_split

df3.head(5)

# Step 1
# Generating the TF-IDF matrix from the 'Payload_Cleaned' column.
# The `fit_transform` method converts the cleaned payload text into a numerical matrix
# where each row represents a payload and each column represents a unique token/word's TF-IDF score.
# The `toarray()` method converts the sparse matrix output of TF-IDF into a dense NumPy array,
# ensuring that the result can be directly used for further processing or modeling.

df3['Payload_Cleaned'] = df3['Payload_Cleaned'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))

# Extracting X features and assigning the vectorizer to X before splitting
X = tfidf_vectorizer.fit_transform(df3['Payload_Cleaned']).toarray()

# Step 2: Preparing the Labels (giving identification to them). def label before assigning to y is very important
def assign_label(row):
    if row['SQLInjection'] == 1:
        return 0  # It means this is SQL Injection
    elif row['XSS'] == 1:
        return 1  # Cross-Site Scripting
    elif row['Normal'] == 1:
        return 2  # Normal Payload
    return -1  # Default/error case for unexpected data

df3['Label'] = df3.apply(assign_label, axis=1) # Apply the custom labeling function

# Extracting y features and assigning labels to y before splitting
y = df3['Label']

# Step 3: Split Data into Train and Test Sets
# Using the DataFrame index directly for splitting
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Storing Predictions (Using iloc for position-based indexing)
#df3.iloc[X_test, df3.columns.get_loc('y_pred_svm')] = y_pred_svm  # or any other predictions

print(df3[['SQLInjection', 'XSS', 'Normal']].sum())

print(y_train.value_counts())

# Check the number of rows in df3
num_rows = df3.shape[0]
print(f"Number of rows in df3: {num_rows}")

# Check the number of rows in df3
num_rows = df3.shape[0]
print(f"Number of rows in df3: {num_rows}")

df3.head(5)

df3 = df3.reset_index(drop=True)
df3.head(5)