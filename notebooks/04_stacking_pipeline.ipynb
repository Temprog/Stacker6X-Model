{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stack Ensemble Pipeline for Stacker6X"
      ],
      "metadata": {
        "id": "M_hbqY-BkAcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports & Setup\n",
        "This notebook imports all necessary libraries and modules using `from utils.imports import *`, which centralizes all dependencies required for training. See `utils/imports.py` for full details.\n"
      ],
      "metadata": {
        "id": "UGL-36KW9UKl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNXXUq-y5aOM"
      },
      "outputs": [],
      "source": [
        "# Imports from utils.imports\n",
        "from utils.imports import np, train_test_split, SVC, accuracy_score, classification_report, confusion_matrix, plt, sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition of Stacker6X"
      ],
      "metadata": {
        "id": "ujoJcDm7Qj52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Branding the model (modular ensemble model, with architecture - (ie with base models, meta-model) and why it was chosen.)\n",
        "# StackerX6 is a stacking ensemble that combines six powerful classifiers (SVM, Logistic Regression, Neural Networks, Random Forest, Extra Trees,\n",
        "# and Gradient Boosting) with a Random Forest as the meta-model. It is designed for robust performance on tabular data for classification tasks.\n",
        "# It is a fusion of six models into a stacking ensemble, leveraging the strength of diverse classifiers.\n",
        "\n",
        "class Stacker6X:\n",
        "    \"\"\"\n",
        "    Stacker6X: A custom stacking ensemble model.\n",
        "\n",
        "    Base Models:\n",
        "        - Logistic Regression (LR)\n",
        "        - Neural Networks (NN)\n",
        "        - Random Forest (RF)\n",
        "        - Extra Trees (ET)\n",
        "        - Gradient Boosting (GB)\n",
        "\n",
        "    Meta-Model:\n",
        "        - Reused SVM (97% Accuracy)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lr_model, nn_model, rf_model, et_model, gb_model, svm_model):\n",
        "        self.svm_model = None  # Exclude SVM as a base model\n",
        "        self.lr_model = lr_model\n",
        "        self.nn_model = nn_model\n",
        "        self.rf_model = rf_model\n",
        "        self.et_model = et_model\n",
        "        self.gb_model = gb_model\n",
        "        self.meta_model = svm_model  # Reuse the trained SVM as the meta-model\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Trains the meta-model using predictions from the base models.\n",
        "        \"\"\"\n",
        "        # Generate probabilities from base models\n",
        "        lr_probs = self.lr_model.predict_proba(X_train)\n",
        "        nn_probs = self.nn_model.predict_proba(X_train)\n",
        "        rf_base_probs = self.rf_model.predict_proba(X_train)\n",
        "        et_probs = self.et_model.predict_proba(X_train)\n",
        "        gb_probs = self.gb_model.predict_proba(X_train)\n",
        "\n",
        "        # Combine probabilities into a single feature set\n",
        "        stacked_features_train = np.hstack([lr_probs, nn_probs, rf_base_probs, et_probs, gb_probs])\n",
        "\n",
        "        # Train the meta-model (already trained SVM is reused here)\n",
        "        self.meta_model.fit(stacked_features_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        Makes predictions using the stacking ensemble.\n",
        "        \"\"\"\n",
        "        # Generate probabilities from base models\n",
        "        lr_probs = self.lr_model.predict_proba(X_test)\n",
        "        nn_probs = self.nn_model.predict_proba(X_test)\n",
        "        rf_base_probs = self.rf_model.predict_proba(X_test)\n",
        "        et_probs = self.et_model.predict_proba(X_test)\n",
        "        gb_probs = self.gb_model.predict_proba(X_test)\n",
        "\n",
        "        # Combine probabilities into a single feature set\n",
        "        stacked_features_test = np.hstack([lr_probs, nn_probs, rf_base_probs, et_probs, gb_probs])\n",
        "\n",
        "        # Predict with the meta-model (trained SVM)\n",
        "        return self.meta_model.predict(stacked_features_test)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evaluates the model's performance.\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        report = classification_report(y_test, y_pred)\n",
        "        return accuracy, report\n",
        "\n",
        "# fusion_model is an instance of the Stacker6X class. It's a specific object in your computer's memory that has all the properties (like lr_model, nn_model, etc.) and methods (fit, predict, evaluate) defined by the Stacker6X class.\n",
        "# Initializing Stacker6X with pre-trained models (pre-trained base models and meta-model)\n",
        "fusion_model = Stacker6X(lr_model, nn_model, rf_model, et_model, gb_model, svm_model)\n"
      ],
      "metadata": {
        "id": "E3D3XdeCNg6I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}